{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Create a LLM Eval Application\"\n",
    "author: \"Isaac Flath\"\n",
    "date: \"2020-06-10\"\n",
    "description: \"A walkthrough of creating an evaluation framework with Shiny for Python\"\n",
    "categories: [LLMs, Shiny]\n",
    "image: \"../_TopicImages/LLMs.jpg\"\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "When using LLMs in practice:\n",
    "\n",
    "1. Evals are the most important thing to get right when working with LLMs\n",
    "1. The right evals are very use-case and domain dependent \n",
    "\n",
    "Because of this it is important to:\n",
    "\n",
    "1. Have as much flexibility possible when working with evals.\n",
    "1. Be able to optimize your eval workflow\n",
    "\n",
    "The best way to do get that is to build your own eval application.  Thanks to [Shiny for Python](https://shiny.posit.co/py/) this isn't as monumental of a task as it may sound and can be done completely in Python.  This post will walk through building a sample eval application to help familiarize you with the process.\n",
    "\n",
    ":::{.callout-note}\n",
    "If you want to use a framework, I recommend [inspect_ai](https://github.com/UKGovernmentBEIS/inspect_ai)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Evals\n",
    "\n",
    "For this example I doing a simple task.  Given an address I want the LLM to clean and standardize it and return a JSON.  While this isn't the best LLM use-case, this is a really great use case for having lots of simple and easy evals to test.  This will let us focus on building the framework and not get bogged down with the challenges of LLM evals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage\n",
    "\n",
    "You need to have a good and organized way to store inputs, outputs, and the test results to be queried.  There are many tools to do this and many formats, but I like to use sqlite.  [The sqlite-utils](https://sqlite-utils.datasette.io/en/stable/python-api.html) is extremely helpful and helps manage things like automatically creating tables on first insert, and automatically adding missing columns on insert.  It also provides a flexible API for querying in python.\n",
    "\n",
    ":::{.callout-note}\n",
    "Database normalization is a skill very few people actually can apply effectively in practice (you'll hear things like semi-normalized or it's mostly normalized, even when its not at all normalized).  If you master it and actually apply it you will be able to easily delegate tasks, transition off projects, and rely on others for maintenence and debugging in production.\n",
    "\n",
    "If you don't, you will end up being the only reliable repository of information and so will be stuck answering questions and writing queries for other people indefinitely.  There is simply no reliable way to transfer expert knowledge of a relational databased that was not built on best-practice normalization.  You will be forever stuck hoping that others will step up and take over, but they simply won't be able to.\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
