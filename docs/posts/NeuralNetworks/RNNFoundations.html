<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.156">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Isaac Flath">
<meta name="dcterms.date" content="2020-08-22">
<meta name="description" content="What is an RNN? How does NLP work?">

<title>myblog - NLP Recurrent NN Foundations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">myblog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/isaac-flath"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/isaac_flath"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://sigmoid.social/web/@isaac_flath"><i class="bi bi-mastodon" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">NLP Recurrent NN Foundations</h1>
                  <div>
        <div class="description">
          What is an RNN? How does NLP work?
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Neural Networks</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Isaac Flath </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 22, 2020</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#credit-where-credit-is-due" id="toc-credit-where-credit-is-due" class="nav-link active" data-scroll-target="#credit-where-credit-is-due"><span class="toc-section-number">1</span>  Credit Where Credit is Due</a></li>
  <li><a href="#data-setup" id="toc-data-setup" class="nav-link" data-scroll-target="#data-setup"><span class="toc-section-number">2</span>  Data Setup</a>
  <ul class="collapse">
  <li><a href="#get-the-data" id="toc-get-the-data" class="nav-link" data-scroll-target="#get-the-data"><span class="toc-section-number">2.0.1</span>  Get the Data</a></li>
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization"><span class="toc-section-number">2.0.2</span>  Tokenization</a></li>
  <li><a href="#numericalization" id="toc-numericalization" class="nav-link" data-scroll-target="#numericalization"><span class="toc-section-number">2.0.3</span>  Numericalization</a></li>
  <li><a href="#sequence-definition" id="toc-sequence-definition" class="nav-link" data-scroll-target="#sequence-definition"><span class="toc-section-number">2.0.4</span>  Sequence Definition</a></li>
  <li><a href="#dataloader" id="toc-dataloader" class="nav-link" data-scroll-target="#dataloader"><span class="toc-section-number">2.0.5</span>  Dataloader</a></li>
  </ul></li>
  <li><a href="#language-model" id="toc-language-model" class="nav-link" data-scroll-target="#language-model"><span class="toc-section-number">3</span>  Language Model</a>
  <ul class="collapse">
  <li><a href="#naive-model" id="toc-naive-model" class="nav-link" data-scroll-target="#naive-model"><span class="toc-section-number">3.0.1</span>  Naive Model</a></li>
  <li><a href="#rnn-number-1" id="toc-rnn-number-1" class="nav-link" data-scroll-target="#rnn-number-1"><span class="toc-section-number">3.0.2</span>  RNN Number 1</a></li>
  <li><a href="#rnn-number-2" id="toc-rnn-number-2" class="nav-link" data-scroll-target="#rnn-number-2"><span class="toc-section-number">3.0.3</span>  RNN Number 2</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="toc-section-number">4</span>  Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.text.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="credit-where-credit-is-due" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Credit Where Credit is Due</h1>
<p>The concept and techniques covered in this post are covered in much greater detail in <a href="https://www.amazon.com/gp/product/1492045527/ref=ppx_yo_dt_b_asin_image_o08_s00?ie=UTF8&amp;psc=1%7C">Jeremy Howard and Sylvain Gugger’s book</a>. If you like this post, you should buy the book as you’ll probably like it even more!</p>
</section>
<section id="data-setup" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Data Setup</h1>
<section id="get-the-data" class="level3" data-number="2.0.1">
<h3 data-number="2.0.1" class="anchored" data-anchor-id="get-the-data"><span class="header-section-number">2.0.1</span> Get the Data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.HUMAN_NUMBERS)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>lines <span class="op">=</span> L()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(path<span class="op">/</span><span class="st">"train.txt"</span>) <span class="im">as</span> f: lines <span class="op">+=</span> L(<span class="op">*</span>f.readlines())</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(path<span class="op">/</span><span class="st">"valid.txt"</span>) <span class="im">as</span> f: lines <span class="op">+=</span> L(<span class="op">*</span>f.readlines())</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>lines</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(#9998) ['one \n','two \n','three \n','four \n','five \n','six \n','seven \n','eight \n','nine \n','ten \n'...]</code></pre>
</div>
</div>
</section>
<section id="tokenization" class="level3" data-number="2.0.2">
<h3 data-number="2.0.2" class="anchored" data-anchor-id="tokenization"><span class="header-section-number">2.0.2</span> Tokenization</h3>
<p>What is Tokenization?</p>
<p>Tokenization is about getting ‘tokens’ of language that have meaning. A word could be a token as it has meaning. A piece of punctuation could be a token as it has meaning. If a work is in all capital letters that could be a token. A portion of a word could be a token (ie dis) because a word beginning with dis has meaning. There are many many ways to tokenize, for this post I will use the most simple approach. That is, I will split based on spaces to make each word a token.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="st">' . '</span>.join([l.strip() <span class="cf">for</span> l <span class="kw">in</span> lines])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> L(<span class="op">*</span>txt.split(<span class="st">' '</span>))<span class="op">;</span> tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(#63095) ['one','.','two','.','three','.','four','.','five','.'...]</code></pre>
</div>
</div>
</section>
<section id="numericalization" class="level3" data-number="2.0.3">
<h3 data-number="2.0.3" class="anchored" data-anchor-id="numericalization"><span class="header-section-number">2.0.3</span> Numericalization</h3>
<p>Now that things are split into tokens, we need to start thinking about how to feed it to a Neural Network. Neural Networks rely on multiplication and addition, and we can’t do that with a word. Somehow we need to convert these tokens to numbers. That is what Numericalization is all about. We will do this in a few steps:</p>
<ol type="1">
<li>Get a unique list of all tokens (v)</li>
<li>Assign a number to each of token (vocab)</li>
<li>Replace tokens with numbers (nums)</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a unique list of all tokens (v)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> tokens.unique()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign a number to each of token (vocab)</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> {v:i <span class="cf">for</span> i,v <span class="kw">in</span> <span class="bu">enumerate</span>(v)}<span class="op">;</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># We can lookup the number associated with a token like this</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>vocab[<span class="st">'fifty'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>23</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace tokens with numbers (nums)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>nums <span class="op">=</span> L(vocab[tok] <span class="cf">for</span> tok <span class="kw">in</span> tokens)<span class="op">;</span> nums</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(#63095) [0,1,2,1,3,1,4,1,5,1...]</code></pre>
</div>
</div>
</section>
<section id="sequence-definition" class="level3" data-number="2.0.4">
<h3 data-number="2.0.4" class="anchored" data-anchor-id="sequence-definition"><span class="header-section-number">2.0.4</span> Sequence Definition</h3>
<p>Now that we have tokens in the form of numbers, we need to create out inputs and outputs to the model. For this we need to organize our data into dependent and independent variables. Let’s use the preceding 3 words to predict the next word. Below, we see the same thing in 2 ways - one with tokens and one with numbers. These are the same thing, just translating the tokens to numbers using the vocab above.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Sequence Length (<code>sl</code>) will be 3, because we are using a sequence of 3 words to predict the next word.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>sl <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># For example, we will use the tokens 'one','.', and 'two' to predict '.'</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>L((tokens[i:i<span class="op">+</span>sl], tokens[i<span class="op">+</span>sl]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(tokens)<span class="op">-</span>sl<span class="op">-</span><span class="dv">1</span>,sl))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(#21031) [((#3) ['one','.','two'], '.'),((#3) ['.','three','.'], 'four'),((#3) ['four','.','five'], '.'),((#3) ['.','six','.'], 'seven'),((#3) ['seven','.','eight'], '.'),((#3) ['.','nine','.'], 'ten'),((#3) ['ten','.','eleven'], '.'),((#3) ['.','twelve','.'], 'thirteen'),((#3) ['thirteen','.','fourteen'], '.'),((#3) ['.','fifteen','.'], 'sixteen')...]</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>seqs <span class="op">=</span> L((tensor(nums[i:i<span class="op">+</span>sl]), nums[i<span class="op">+</span>sl]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(nums)<span class="op">-</span>sl<span class="op">-</span><span class="dv">1</span>,sl))<span class="op">;</span> seqs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]</code></pre>
</div>
</div>
</section>
<section id="dataloader" class="level3" data-number="2.0.5">
<h3 data-number="2.0.5" class="anchored" data-anchor-id="dataloader"><span class="header-section-number">2.0.5</span> Dataloader</h3>
<p>Now we need to create our dataloader. The <code>dataloader</code> is just packaging it into batches, and not doing any transformations or changes to the data. What we saw above is what will be given to the model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>cut <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(seqs) <span class="op">*</span> <span class="fl">0.8</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataLoaders.from_dsets(seqs[:cut],seqs[cut:],bs<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>dls2 <span class="op">=</span> DataLoader(seqs[:cut],bs<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>dls3 <span class="op">=</span> DataLoader(seqs[cut:],bs<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>dls4 <span class="op">=</span> DataLoaders(dls3,dls3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="language-model" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Language Model</h1>
<section id="naive-model" class="level3" data-number="3.0.1">
<h3 data-number="3.0.1" class="anchored" data-anchor-id="naive-model"><span class="header-section-number">3.0.1</span> Naive Model</h3>
<p>First, let’s figure out a baseline for what is the best ‘non-stupid’ model we can come up with. If a model can’t beat this score, then it’s not worth anything.</p>
<p>The approach we will take will be to predict the most common token every time. If we do that we get about a 15% accuracy.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>n,counts <span class="op">=</span> <span class="dv">0</span>,torch.zeros(<span class="bu">len</span>(vocab))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x,y <span class="kw">in</span> dls.valid:</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">+=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> range_of(vocab): counts[i] <span class="op">+=</span> (y<span class="op">==</span>i).<span class="bu">long</span>().<span class="bu">sum</span>()</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> torch.argmax(counts)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>idx, v[idx.item()], counts[idx].item()<span class="op">/</span>n</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(29), 'thousand', 0.15165200855716662)</code></pre>
</div>
</div>
</section>
<section id="rnn-number-1" class="level3" data-number="3.0.2">
<h3 data-number="3.0.2" class="anchored" data-anchor-id="rnn-number-1"><span class="header-section-number">3.0.2</span> RNN Number 1</h3>
<section id="code" class="level5" data-number="3.0.2.0.1">
<h5 data-number="3.0.2.0.1" class="anchored" data-anchor-id="code"><span class="header-section-number">3.0.2.0.1</span> Code</h5>
<p>We are going to make the simplest RNN we can. Here’s a quick explanation of the code below.</p>
<p><code>for i in range(sl):</code> Because we are feeding in a number of tokens based on our sequence length, sl, which was defined as 3. We will have 3 steps, 1 per token.</p>
<p><code>h = h + self.i_h(x[:,i])</code> For each input token we will run our input to hidden function. We are indexing to grab the column in our embedding matrix that corresponds with the token, and adding that. All this is doing is adding the embedding for the particular token.</p>
<p><code>h = F.relu(self.h_h(h))</code> We then run our hidden to hidden function (h_h), which is a linear layer (y = wx + b). We do a ReLu of that, which is just replacing any negative values with 0.</p>
<p><code>return self.h_o(h)</code> We then run our hidden to output function (h_o), which is another linear layer, but it is outputing the prediction of which word is next. Naturally, this is the size of our vocabulary.</p>
<p>Wrap all that in a class and it looks like the below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LM1(Module):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_sz, n_hidden):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_h <span class="op">=</span> nn.Embedding(vocab_sz, n_hidden)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_h <span class="op">=</span> nn.Linear(n_hidden, n_hidden)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_o <span class="op">=</span> nn.Linear(n_hidden,vocab_sz)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(sl):</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> h <span class="op">+</span> <span class="va">self</span>.i_h(x[:,i])</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> F.relu(<span class="va">self</span>.h_h(h))</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.h_o(h)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can run it below and see that we get almost 50% accuracy before we overfit, which is great considering the most common token only appears 15% of the time.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, LM1(<span class="bu">len</span>(vocab), <span class="dv">64</span>), loss_func<span class="op">=</span>F.cross_entropy, metrics<span class="op">=</span>accuracy)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">4</span>, <span class="fl">1e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.505863</td>
      <td>2.136583</td>
      <td>0.458046</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.602575</td>
      <td>1.847033</td>
      <td>0.480865</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.503249</td>
      <td>1.727588</td>
      <td>0.492275</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.436492</td>
      <td>1.771485</td>
      <td>0.410506</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</section>
<section id="tensors" class="level5" data-number="3.0.2.0.2">
<h5 data-number="3.0.2.0.2" class="anchored" data-anchor-id="tensors"><span class="header-section-number">3.0.2.0.2</span> Tensors</h5>
<p>So what is it REALLY doing? To understand that, I find it helpful to think about the matrix/tensor sizes at each step.</p>
<p><strong>Embeddings</strong></p>
<p>Let’s start with our input_hidden. Our Embedding matrix is has 64 weights (n_hidden) for each token in our vocabulary. So that looks like this:</p>
<p><span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64-weights} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}30-tokens\)</span></p>
<p>Now all the embedding layer does is get the correct columns. So for the first word in the sequence we get the index, then look it up in the embedding matrix. That 1 index location turns into the 64 weights.</p>
<p><span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots \\ \cdots \\ \cdots \\ \cdots \\ \cdots \\ \cdots \\ \end{bmatrix}}_{\displaystyle token-idx} \left.\vphantom{\begin{bmatrix} \cdots \\ \cdots \\ \cdots \\ \cdots \\ \cdots \\ \cdots \\ \end{bmatrix}}\right\}128-bs\)</span> <span class="math inline">\(==\)</span> lookup in embedding matrix <span class="math inline">\(==&gt;\)</span> <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}128\)</span></p>
<p><strong>Hidden Linear Layer</strong></p>
<p>Next, we have out hidden_hidden. We have our 128x64 matrix from our embedding lookup and we need to do a linear layer.</p>
<p><span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64-weights} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}128-bs\)</span> <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}64\)</span> <span class="math inline">\(+\)</span> <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64-bias} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}1\)</span> <span class="math inline">\(=\)</span> <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64-weights} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}128-bs\)</span> ===ReLu - Replace all negatives with 0 ===&gt; <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64-weights} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}128-bs\)</span></p>
<p>And we do the above for however long our sequence is, in our case 3. So for each token we do the above. We start with 0 on the first loop, and each subsequent loop through we add onto that.</p>
<p><strong>Ouput Linear Layer</strong></p>
<p>We ended with a 128x64 matrix, which isn’t exactly what we want. We have 30 words, so we want to know which one of the 30 is most likely. Specifically for each of the 128 items in our batch, we want 30 scores (1 for each word in our vocab). So we do a similar step as our hidden linear layer, but adjust the number of weights so we end up with the matrix of the appropriate size.</p>
<p><span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 64-weights} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}128-bs\)</span> <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots\\ \cdots &amp; \cdots\\ \cdots &amp; \cdots\\ \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 30} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots\\ \cdots &amp; \cdots\\ \cdots &amp; \cdots\\ \cdots &amp; \cdots\\ \end{bmatrix}}\right\}64\)</span> <span class="math inline">\(+\)</span> <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 30-bias} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}1\)</span> <span class="math inline">\(=\)</span> <span class="math inline">\(\underbrace{ \begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}_{\displaystyle 30-preds} \left.\vphantom{\begin{bmatrix} \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\ \end{bmatrix}}\right\}128-bs\)</span></p>
</section>
</section>
<section id="rnn-number-2" class="level3" data-number="3.0.3">
<h3 data-number="3.0.3" class="anchored" data-anchor-id="rnn-number-2"><span class="header-section-number">3.0.3</span> RNN Number 2</h3>
<p>Now that we have a simple model, how do we improve it? There are many steps that need to be taken to get to a cutting edge model. We’ll do one improvement, then leave the rest for future blog posts.</p>
<p>One thing that was a bit odd is in the training loop we reset back to 0 every time. What I mean by that, is we would loop through each of the 3 tokens, output our predictions for those, update the weights, then reset back for a new set. This isn’t really how language works. Language has a pattern and a sequence to it. The further back you go the less important, but even things said a couple minutes ago could be important. Could you imagine holding a conversation if you could only remember and respond based on the last 3 words?</p>
<p>So let’s fix this problem. We will move our h=0 up to the initialization of the class, and never reset back to 0. Instead, we will continuously keep adding to it. We will only update the last batch of weights (as if we updated all of them by the 1000th one we would be updating far to many weights to compute). We call this “detaching” it. Ultimately we are left with the same thing, but if has a memory of previous sequences beyond the one we are processing! Let’s see if it makes things better.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LM2(Module):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_sz, n_hidden):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_h <span class="op">=</span> nn.Embedding(vocab_sz, n_hidden)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_h <span class="op">=</span> nn.Linear(n_hidden, n_hidden)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h_o <span class="op">=</span> nn.Linear(n_hidden,vocab_sz)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h <span class="op">=</span> <span class="va">self</span>.h <span class="op">+</span> <span class="va">self</span>.i_h(x[:,i])</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h <span class="op">=</span> F.relu(<span class="va">self</span>.h_h(<span class="va">self</span>.h))</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.h_o(<span class="va">self</span>.h)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h <span class="op">=</span> <span class="va">self</span>.h.detach()</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To do this we need to take care that our data is in the appropriate order, so let’s do a few tranformations to make that work.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="bu">len</span>(seqs)<span class="op">//</span>bs</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>m,bs,<span class="bu">len</span>(seqs)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> group_chunks(ds, bs):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> <span class="bu">len</span>(ds) <span class="op">//</span> bs</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    new_ds <span class="op">=</span> L()</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(m): new_ds <span class="op">+=</span> L(ds[i <span class="op">+</span> m<span class="op">*</span>j] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(bs))</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_ds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>cut <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(seqs) <span class="op">*</span> <span class="fl">0.8</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataLoaders.from_dsets(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    group_chunks(seqs[:cut], bs), </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    group_chunks(seqs[cut:], bs), </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    bs<span class="op">=</span>bs, drop_last<span class="op">=</span><span class="va">True</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, LM2(<span class="bu">len</span>(vocab), <span class="dv">64</span>), loss_func<span class="op">=</span>F.cross_entropy, metrics<span class="op">=</span>accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">10</span>, <span class="fl">3e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.342321</td>
      <td>1.897249</td>
      <td>0.481689</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.453624</td>
      <td>1.713581</td>
      <td>0.449707</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.154838</td>
      <td>1.680148</td>
      <td>0.519775</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.042766</td>
      <td>1.566625</td>
      <td>0.517822</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.969852</td>
      <td>1.633654</td>
      <td>0.542480</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.937066</td>
      <td>1.581196</td>
      <td>0.559570</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.882712</td>
      <td>1.660810</td>
      <td>0.588379</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.844926</td>
      <td>1.595611</td>
      <td>0.597656</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.808309</td>
      <td>1.613600</td>
      <td>0.605225</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.797358</td>
      <td>1.621867</td>
      <td>0.605713</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>And we are up from about 50% accuracy to about 60%!</p>
</section>
</section>
<section id="conclusion" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Conclusion</h1>
<p>Hopefully from this post you gained an understanding of the fundamental concepts behind NLP using Neural Networks. While this isn’t cutting edge, the fundamental principles must be understood if you want to gain an intuition about what types of things might work.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>